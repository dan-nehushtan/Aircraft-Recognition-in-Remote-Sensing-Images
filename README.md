<div align="center">

# âœˆï¸ Aircraft Recognition in Remote Sensing Images

**Deep Learning for Fine-Grained Aircraft Classification**

[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org)
[![Hugging Face](https://img.shields.io/badge/ğŸ¤—_Hugging_Face-FFD21E?style=for-the-badge)](https://huggingface.co)
[![Jupyter](https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white)](https://jupyter.org)

*MECH 3465 â€” Robotics & Machine Intelligence Coursework*

**Authors:** Dan Nehushtan Â· Louie Burns

---

</div>

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Dataset](#-dataset)
- [Approach](#-approach)
- [Model Architectures](#-model-architectures)
- [Results](#-results)
- [Repository Structure](#-repository-structure)
- [Development Journey](#-development-journey)
- [Getting Started](#-getting-started)
- [Key Findings](#-key-findings)

---

## ğŸ” Overview

This project explores **fine-grained aircraft classification** from remote sensing imagery using deep learning. Starting from a minimal single-layer CNN baseline, we iteratively developed and evaluated increasingly sophisticated models â€” culminating in experiments with **ResNet50** transfer learning and **Vision Transformers (ViT)**.

The primary task focused on classifying aircraft by **manufacturer** (e.g., Boeing, Airbus, Cessna), with additional exploration of **family** and **variant** classification hierarchies.

### Objectives

- Build a baseline CNN classifier for aircraft manufacturer recognition
- Systematically improve performance through architectural and training enhancements
- Explore transfer learning with pre-trained models (ResNet50, ViT)
- Analyse the impact of data preprocessing, augmentation, and class balancing strategies

---

## ğŸ“Š Dataset

The project uses the **FGVC Aircraft Recognition Dataset** â€” a benchmark for fine-grained visual categorisation containing **10,000 images** of aircraft.

| Split | Images |
|:------|-------:|
| Train | 3,334 |
| Validation | 3,333 |
| Test | 3,333 |
| **Total** | **10,000** |

### Classification Hierarchies

| Level | Classes | Description | Example |
|:------|--------:|:------------|:--------|
| **Manufacturer** | 30 | Aircraft maker | Boeing, Airbus, Cessna |
| **Family** | 70 | Aircraft model family | Boeing 737, A320, F-16 |
| **Variant** | 100 | Specific model variant | 737-800, A320, 777-300 |

### Manufacturers in Dataset

> Airbus Â· ATR Â· Antonov Â· Beechcraft Â· Boeing Â· Bombardier Aerospace Â· British Aerospace Â· Canadair Â· Cessna Â· Cirrus Aircraft Â· Dassault Aviation Â· Dornier Â· Douglas Aircraft Company Â· Embraer Â· Eurofighter Â· Fairchild Â· Fokker Â· Gulfstream Aerospace Â· Ilyushin Â· Lockheed Corporation Â· Lockheed Martin Â· McDonnell Douglas Â· Panavia Â· Piper Â· Robin Â· Saab Â· Supermarine Â· Tupolev Â· Yakovlev Â· de Havilland

---

## ğŸ¯ Approach

### Strategy

The manufacturer classification task was chosen strategically â€” it offers **fewer classes (30)** than family (70) or variant (100) while providing more balanced class distributions. For the final model, the **top 5 manufacturers by sample count** were dynamically selected to ensure adequate training data per class.

### Progressive Improvement Pipeline

```
Baseline CNN          â†’    Data Augmentation     â†’    Batch Normalisation
(1 conv, 64Ã—64)            (flip, rotation)            + Deeper Network
        â†“                        â†“                          â†“
  LR Scheduling        â†’    Transfer Learning     â†’    Vision Transformer
  (StepLR decay)            (ResNet50)                  (ViT - HuggingFace)
```

---

## ğŸ—ï¸ Model Architectures

### 1. Baseline â€” SimpleCNN

The minimal starting point for benchmarking.

```
Input (3Ã—64Ã—64)
  â†’ Conv2d(3â†’16, 3Ã—3) â†’ ReLU â†’ MaxPool2d(2Ã—2)
  â†’ Flatten â†’ Linear â†’ Output (5 classes)
```

| Parameter | Value |
|:----------|:------|
| Image Size | 64Ã—64 |
| Optimizer | SGD (lr=0.01) |
| Batch Size | 64 |
| Epochs | 15 |
| Augmentation | None |

### 2. Improved â€” Enhanced CNN

Deeper architecture with regularisation and modern training techniques.

```
Input (3Ã—128Ã—128)  
  â†’ Conv2d(3â†’16) â†’ BatchNorm â†’ ReLU â†’ MaxPool
  â†’ Conv2d(16â†’32) â†’ BatchNorm â†’ ReLU â†’ MaxPool
  â†’ Conv2d(32â†’64) â†’ BatchNorm â†’ ReLU â†’ MaxPool
  â†’ Flatten â†’ Linear(128) â†’ Dropout(0.5) â†’ Output (5 classes)
```

| Parameter | Value |
|:----------|:------|
| Image Size | 128Ã—128 |
| Optimizer | SGD (lr=0.01) |
| Scheduler | StepLR (step=9, Î³=0.5) |
| Batch Size | 32 |
| Epochs | 40 |
| Augmentation | RandomHorizontalFlip, RandomRotation(5Â°) |
| Normalisation | Mean=0.5, Std=0.5 |

### 3. ResNet50 â€” Transfer Learning

Pre-trained ResNet50 with fine-tuned classification head.

| Parameter | Value |
|:----------|:------|
| Image Size | 224Ã—224 |
| Optimizer | AdamW (lr=1e-4) |
| Scheduler | StepLR (step=5, Î³=0.1) |
| Batch Size | 16 |
| Label Smoothing | 0.1 |
| Augmentation | Flip, Rotation(15Â°), ColorJitter |
| Normalisation | ImageNet statistics |

### 4. Vision Transformer (ViT)

Hugging Face `ViTForImageClassification` fine-tuned from `dima806/military_aircraft_image_detection`.

| Parameter | Value |
|:----------|:------|
| Image Size | 224Ã—224 |
| Optimizer | AdamW (lr=2e-7) |
| Batch Size | 64 (train) / 32 (eval) |
| Epochs | 3 |
| Weight Decay | 0.02 |
| Warmup Steps | 50 |
| Class Balancing | RandomOverSampler |

### 5. Custom Residual CNN (EnhancedCNN)

A custom-designed residual network with skip connections.

```
Input (3Ã—224Ã—224)
  â†’ ResidualBlock(3â†’32) â†’ ResidualBlock(32â†’64) â†’ ResidualBlock(64â†’128)
  â†’ AdaptiveAvgPool2d â†’ Flatten â†’ Linear â†’ Output
```

| Parameter | Value |
|:----------|:------|
| Image Size | 224Ã—224 |
| Optimizer | Adam (lr=0.001) |
| Scheduler | StepLR (step=5, Î³=0.5) |
| Epochs | 100 |
| Augmentation | Flip, Rotation(15Â°), ColorJitter, Affine, Grayscale |

---

## ğŸ“ˆ Results

### Improved Model â€” Training Progress (50 Epochs)

| Metric | Best Value | At Epoch |
|:-------|:-----------|:---------|
| **Train Accuracy** | 95.7% | 40 |
| **Test Accuracy** | 52.6% | 44 |
| **F1 Score** | 0.514 | 45 |
| **Train Loss** | 0.299 | 40 |
| **Test Loss** | 1.232 | 22 |

### Training Curve Summary

```
Epoch   Train Acc   Test Acc   F1 Score   Learning Rate
â”€â”€â”€â”€â”€   â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”€â”€â”€â”€â”€â”€â”€â”€   â”€â”€â”€â”€â”€â”€â”€â”€   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  1      33.1%      25.9%      0.129      0.01
  5      61.3%      28.6%      0.167      0.005
 10      77.6%      38.6%      0.356      0.0025
 18      90.0%      51.4%      0.503      0.00125
 25      93.9%      51.7%      0.505      0.0003125
 35      95.3%      52.2%      0.511      7.81e-05
 50      95.6%      52.4%      0.513      9.77e-06
```

### Baseline vs Improved â€” Comparison

| Metric | Baseline | Improved | Improvement |
|:-------|:---------|:---------|:------------|
| Architecture | 1-conv CNN | 3-conv CNN + BN | Deeper + regularised |
| Image Resolution | 64Ã—64 | 128Ã—128 | 4Ã— more pixels |
| Best F1 Score | ~0.38 | ~0.51 | **+34% relative** |
| Training Epochs | 15 | 40â€“50 | Longer training |
| LR Schedule | Fixed | StepLR decay | Adaptive |
| Augmentation | None | Flip + Rotation | Increased variety |

---

## ğŸ“ Repository Structure

```
ğŸ“¦ Aircraft-Recognition-in-Remote-Sensing-Images
â”œâ”€â”€ ğŸ“‚ Actual Coursework/
â”‚   â”œâ”€â”€ ğŸ“‚ FINAL RESULTS/                    â† Final submitted models & metrics
â”‚   â”‚   â”œâ”€â”€ ğŸ““ Baseline Model.ipynb           â† SimpleCNN baseline
â”‚   â”‚   â”œâ”€â”€ ğŸ““ Improved Model.ipynb           â† Enhanced CNN with improvements
â”‚   â”‚   â”œâ”€â”€ ğŸ“Š Epoch_Metrics_Table.csv        â† Training metrics (50 epochs)
â”‚   â”‚   â””â”€â”€ ğŸ† best_model.pth                â† Saved best model weights
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ Code Attempts/                    â† 23 iterative development versions (V1â€“V23)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ Code Attempts - Manufacturer Instead/
â”‚   â”‚   â”œâ”€â”€ ğŸ““ V01 - Base Case.ipynb          â† Initial manufacturer classification
â”‚   â”‚   â”œâ”€â”€ ğŸ““ V03 - Added Batch Normalisation.ipynb
â”‚   â”‚   â”œâ”€â”€ ğŸ““ V06 - Added layers and dropout.ipynb
â”‚   â”‚   â”œâ”€â”€ ğŸ““ V08 - External Models.ipynb    â† ResNet50 transfer learning
â”‚   â”‚   â”œâ”€â”€ ğŸ““ V12 - Exclude Boeing.ipynb     â† Class imbalance experiments
â”‚   â”‚   â””â”€â”€ ... (14 versions total)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ Code Attempts - Analysis and Improvement/
â”‚   â”‚   â”œâ”€â”€ ğŸ““ V01 - Baseline Code.ipynb      â† Family classification baseline
â”‚   â”‚   â”œâ”€â”€ ğŸ““ V05 - Add more layers.ipynb
â”‚   â”‚   â”œâ”€â”€ ğŸ““ ChatGPT Improvements (V6).ipynb â† Custom ResidualBlock CNN
â”‚   â”‚   â””â”€â”€ ... (7 versions total)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ Hugging Face/                     â† ViT transformer experiments
â”‚   â”œâ”€â”€ ğŸ“‚ Lecturer Code Attempts/           â† Template-based experiments
â”‚   â””â”€â”€ ğŸ“‚ dataoriginal/                     â† Dataset labels & annotations
â”‚       â”œâ”€â”€ families.txt                      â† 70 aircraft families
â”‚       â”œâ”€â”€ manufacturers.txt                 â† 30 manufacturers
â”‚       â”œâ”€â”€ variants.txt                      â† 100 variants
â”‚       â”œâ”€â”€ images_box.txt                    â† Bounding box annotations
â”‚       â””â”€â”€ images_{task}_{split}.txt         â† Train/val/test splits
â”‚
â”œâ”€â”€ ğŸ“‚ Group_1_BurnsNehushtan/               â† Final group submission
â”‚   â”œâ”€â”€ ğŸ““ Code.ipynb                        â† Complete submitted notebook
â”‚   â”œâ”€â”€ ğŸ“„ Code.pdf                          â† PDF export
â”‚   â””â”€â”€ ğŸ“„ Report.docx                      â† Written analysis report
â”‚
â”œâ”€â”€ ğŸ“‚ Coursework 1/                         â† Earlier development & exploration
â”‚   â”œâ”€â”€ ğŸ““ V2 - military-aircraft-detection-vit.ipynb  â† ViT experiments
â”‚   â”œâ”€â”€ ğŸ““ V8 - Bounding Boxes.ipynb         â† Bounding box preprocessing
â”‚   â””â”€â”€ ... (11 versions)
â”‚
â””â”€â”€ ğŸ“‚ Lab/                                  â† Lab templates & exercises
```

---

## ğŸ”„ Development Journey

The project evolved through **50+ notebook iterations** across multiple classification strategies:

### Phase 1 â€” Initial Exploration
- Started with family classification (70 classes) â€” proved too fine-grained for a simple CNN 
- Explored bounding box preprocessing to crop aircraft from full images
- Investigated the dataset structure and class distributions

### Phase 2 â€” Strategic Pivot to Manufacturer Classification
- Switched to manufacturer classification (30 classes â†’ top 5 selected)
- Built baseline SimpleCNN as a benchmark
- Identified Boeing and Airbus class dominance as a key challenge

### Phase 3 â€” Systematic Improvement
- **V03:** Added Batch Normalisation â†’ improved training stability
- **V04:** Increased batch size â†’ smoother gradient updates
- **V05â€“V06:** Deeper network + Dropout â†’ better feature extraction + regularisation
- **V07:** Increased image resolution (64â†’128) â†’ captured finer details
- **Learning rate scheduling** (StepLR) â†’ prevented overshooting during convergence

### Phase 4 â€” Advanced Approaches
- **ResNet50** transfer learning with ImageNet pre-training
- **Vision Transformer (ViT)** fine-tuning via Hugging Face
- **Custom Residual CNN** with skip connections
- Class exclusion experiments (removing Boeing/Airbus) to study imbalance effects

---

## ğŸš€ Getting Started

### Prerequisites

```bash
pip install torch torchvision matplotlib scikit-learn pandas numpy
pip install transformers datasets  # For ViT experiments
```

### Quick Start

1. **Clone the repository**
   ```bash
   git clone https://github.com/<your-username>/Aircraft-Recognition-in-Remote-Sensing-Images.git
   cd Aircraft-Recognition-in-Remote-Sensing-Images
   ```

2. **Download the FGVC Aircraft Dataset**
   - Place images in the expected directory structure
   - Label files are provided in `Actual Coursework/dataoriginal/`

3. **Run the final models**
   - Open `Actual Coursework/FINAL RESULTS/Baseline Model.ipynb` for the baseline
   - Open `Actual Coursework/FINAL RESULTS/Improved Model.ipynb` for the improved model
   - Open `Group_1_BurnsNehushtan/Code.ipynb` for the complete submission

### Hardware

- Models were developed and tested with **CUDA GPU** support
- The notebooks include automatic GPU detection (`torch.cuda.is_available()`)
- CPU training is supported but significantly slower

---

## ğŸ’¡ Key Findings

1. **Simple CNNs struggle with fine-grained classification** â€” A single-layer CNN on 64Ã—64 images achieved only ~38% F1 on 5-class manufacturer recognition, near random chance

2. **Image resolution matters significantly** â€” Doubling from 64Ã—64 to 128Ã—128 provided meaningful accuracy gains by preserving discriminative aircraft features

3. **Batch Normalisation + Dropout** were the most impactful single architectural additions, improving both training stability and generalisation

4. **Learning rate scheduling is essential** â€” StepLR decay (halving every 9 epochs) allowed the model to converge to better optima than fixed-rate training

5. **Class imbalance is a major challenge** â€” Boeing and Airbus dominate the dataset; intelligent class selection and balancing strategies (like RandomOverSampler) are critical

6. **The gap between train and test accuracy (~43%)** indicates overfitting remains a challenge, suggesting the dataset may be too small for the model complexity or that stronger augmentation / regularisation is needed

7. **Transfer learning (ResNet50, ViT)** represents the most promising direction for future work, leveraging features learned from millions of images

---

## ğŸ› ï¸ Technologies Used

| Technology | Purpose |
|:-----------|:--------|
| **Python 3.8+** | Core language |
| **PyTorch** | Deep learning framework |
| **torchvision** | Image transforms, pre-trained models |
| **Hugging Face Transformers** | ViT model & training |
| **scikit-learn** | Metrics (F1, confusion matrix), oversampling |
| **Matplotlib** | Visualisation & plots |
| **Pandas / NumPy** | Data handling |
| **Jupyter Notebook** | Development environment |
| **CUDA** | GPU acceleration |

---

<div align="center">

**MECH 3465 â€” Robotics & Machine Intelligence**  
University of Leeds Â· 2024/25

</div>