{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe0a73-9a26-4730-b48c-455b1cf87148",
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "\n",
    "#Firstly create a tensor which contains the iamges and their labels\n",
    "\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79517f0e-4b25-416d-8552-06f269e0b440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {'Boeing 707': 1, 'Boeing 727': 2, 'Boeing 737': 3, 'Boeing 747': 4, 'Boeing 757': 5, 'Boeing 767': 6, 'Boeing 777': 7, 'A300': 8, 'A310': 9, 'A320': 10, 'A330': 11, 'A340': 12, 'A380': 13, 'ATR-42': 14, 'ATR-72': 15, 'An-12': 16, 'BAE 146': 17, 'BAE-125': 18, 'Beechcraft 1900': 19, 'Boeing 717': 20, 'C-130': 21, 'C-47': 22, 'CRJ-200': 23, 'CRJ-700': 24, 'Cessna 172': 25, 'Cessna 208': 26, 'Cessna Citation': 27, 'Challenger 600': 28, 'DC-10': 29, 'DC-3': 30, 'DC-6': 31, 'DC-8': 32, 'DC-9': 33, 'DH-82': 34, 'DHC-1': 35, 'DHC-6': 36, 'Dash 8': 37, 'DR-400': 38, 'Dornier 328': 39, 'Embraer E-Jet': 40, 'EMB-120': 41, 'Embraer ERJ 145': 42, 'Embraer Legacy 600': 43, 'Eurofighter Typhoon': 44, 'F-16': 45, 'F/A-18': 46, 'Falcon 2000': 47, 'Falcon 900': 48, 'Fokker 100': 49, 'Fokker 50': 50, 'Fokker 70': 51, 'Global Express': 52, 'Gulfstream': 53, 'Hawk T1': 54, 'Il-76': 55, 'L-1011': 56, 'MD-11': 57, 'MD-80': 58, 'MD-90': 59, 'Metroliner': 60, 'King Air': 61, 'PA-28': 62, 'SR-20': 63, 'Saab 2000': 64, 'Saab 340': 65, 'Spitfire': 66, 'Tornado': 67, 'Tu-134': 68, 'Tu-154': 69, 'Yak-42': 70}\n",
      "Image tensor shape: torch.Size([3334, 3, 128, 128])\n",
      "Label tensor shape: torch.Size([3334])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Define the folder containing the images\n",
    "image_folder = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images'\n",
    "\n",
    "# Path to the text file\n",
    "label_file = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images_family_train.txt'\n",
    "\n",
    "# Define transformations for image processing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize to 128x128 (can be adjusted)\n",
    "    transforms.ToTensor()          # Convert to tensor\n",
    "])\n",
    "\n",
    "# Synchronize data collection\n",
    "image_data = []\n",
    "labels = []\n",
    "\n",
    "with open(label_file, 'r') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(maxsplit=1)\n",
    "        if len(parts) != 2:\n",
    "            continue  # Skip malformed lines\n",
    "        filename, label = parts\n",
    "        image_path = os.path.join(image_folder, filename + \".jpg\")\n",
    "        \n",
    "        if os.path.exists(image_path) and label in label_mapping:\n",
    "            try:\n",
    "                image = Image.open(image_path).convert('RGB')\n",
    "                image_tensor = transform(image)\n",
    "                image_data.append(image_tensor)\n",
    "                labels.append(label_mapping[label])\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "# Convert lists to PyTorch tensors\n",
    "image_tensor = torch.stack(image_data)  # Create a tensor from image data\n",
    "label_tensor = torch.tensor(labels)     # Convert labels to tensor\n",
    "\n",
    "# Print label mapping and tensor dimensions for verification\n",
    "print(\"Label Mapping:\", label_mapping)\n",
    "print(\"Image tensor shape:\", image_tensor.shape)\n",
    "print(\"Label tensor shape:\", label_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ffb3b5e-c08d-4300-83aa-9b7fc321759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "\n",
    "#Create the testing data set\n",
    "\n",
    "#########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5406854b-291f-4782-8ab2-91958b3da1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Image Tensor Shape: torch.Size([3333, 3, 128, 128])\n",
      "Test Label Tensor Shape: torch.Size([3333])\n"
     ]
    }
   ],
   "source": [
    "# Path to the testing data file\n",
    "testing_file = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images_family_test.txt'\n",
    "\n",
    "test_image_data = []\n",
    "test_labels = []\n",
    "\n",
    "with open(testing_file, 'r') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(maxsplit=1)  # Split into filename and label\n",
    "        if len(parts) != 2:\n",
    "            continue  # Skip malformed lines\n",
    "        filename, label = parts\n",
    "\n",
    "        if label not in label_mapping:\n",
    "            print(f\"Warning: Label '{label}' in testing data not found in training labels.\")\n",
    "            continue  # Skip labels not seen during training\n",
    "\n",
    "        image_path = os.path.join(image_folder, filename + \".jpg\")  # Assuming .jpg extension\n",
    "        if os.path.exists(image_path):\n",
    "            try:\n",
    "                image = Image.open(image_path).convert('RGB')  # Open image\n",
    "                image_tensor = transform(image)               # Apply transformations\n",
    "                test_image_data.append(image_tensor)\n",
    "                test_labels.append(label_mapping[label])\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {image_path}: {e}\")\n",
    "        else:\n",
    "            print(f\"File not found: {image_path}\")\n",
    "\n",
    "# Ensure data synchronization\n",
    "assert len(test_image_data) == len(test_labels), \"Mismatch in number of test images and labels!\"\n",
    "\n",
    "# Convert to tensors\n",
    "test_image_tensor = torch.stack(test_image_data)  # Stack images into a tensor\n",
    "test_label_tensor = torch.tensor(test_labels)     # Convert labels to a tensor\n",
    "\n",
    "# Verify shapes\n",
    "print(\"Test Image Tensor Shape:\", test_image_tensor.shape)\n",
    "print(\"Test Label Tensor Shape:\", test_label_tensor.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423ab775-c4f2-4909-bbb5-5564a5b845de",
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "\n",
    "#Creating the CNN\n",
    "\n",
    "########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "baedeee4-0a08-4ec6-a022-0d8dc748b25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/c92d9yg14ts9tqnbfdnwctpc0000gn/T/ipykernel_41951/2350710371.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label_tensor = torch.tensor(labels, dtype=torch.long)  # Ensure labels are integer tensors\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Size mismatch between tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m label_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(labels, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)  \u001b[38;5;66;03m# Ensure labels are integer tensors\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Create TensorDataset\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m TensorDataset(image_tensor, label_tensor)\n\u001b[1;32m     48\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m TensorDataset(test_image_tensor, test_label_tensor)\n\u001b[1;32m     50\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataset.py:205\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtensors: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    206\u001b[0m         tensors[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m tensor\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors\n\u001b[1;32m    207\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize mismatch between tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors\n",
      "\u001b[0;31mAssertionError\u001b[0m: Size mismatch between tensors"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Define the CNN architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)  # Input channels = 3 (RGB), Output channels = 32\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Max pooling\n",
    "        self.fc1_input_size = self._get_flatten_size()\n",
    "        self.fc1 = nn.Linear(self.fc1_input_size, 128)  # Adjusted input size\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def _get_flatten_size(self):\n",
    "        # Use a dummy tensor to calculate the flattened size\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 3, 128, 128)  # Example input tensor\n",
    "            x = self.pool(torch.relu(self.conv1(dummy_input)))\n",
    "            x = self.pool(torch.relu(self.conv2(x)))\n",
    "            return x.view(1, -1).size(1)  # Flatten and get the size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Parameters\n",
    "num_classes = len(label_mapping)  # Number of unique labels\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Ensure label tensor shape is correct\n",
    "label_tensor = label_tensor.squeeze()  # Remove extra dimensions if any\n",
    "\n",
    "image_tensor = torch.stack(image_data)  # Ensure proper tensor stacking for images\n",
    "label_tensor = torch.tensor(labels, dtype=torch.long)  # Ensure labels are integer tensors\n",
    "\n",
    "# Create TensorDataset\n",
    "train_dataset = TensorDataset(image_tensor, label_tensor)\n",
    "test_dataset = TensorDataset(test_image_tensor, test_label_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = CNN(num_classes=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()  # Use cross-entropy loss for classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training the CNN\n",
    "print(\"Training the CNN...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Optimize weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "# Evaluate the CNN on the test set\n",
    "print(\"Evaluating the CNN...\")\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the class with the highest score\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762749d2-d93d-40eb-8e7c-7c09a6fc9017",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### \n",
    "\n",
    "#F1 Calculation Score\n",
    "\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33ff0e3-1074-4bda-b50a-0d61197d63cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Evaluate the CNN on the test set and calculate accuracy and F1-score\n",
    "print(\"Evaluating the CNN...\")\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the class with the highest score\n",
    "        all_labels.extend(labels.numpy())      # Store true labels\n",
    "        all_predictions.extend(predicted.numpy())  # Store predictions\n",
    "\n",
    "# Calculate Accuracy\n",
    "correct = sum(1 for true, pred in zip(all_labels, all_predictions) if true == pred)\n",
    "total = len(all_labels)\n",
    "accuracy = 100 * correct / total\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
