{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92256fee-ab8f-4133-86e4-d5447f89d1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "\n",
    "\n",
    "#THIS FIRST SECTION WILL IMPORT THE TRAINING DATA AND SETUP THE INFORMATION FOR TRAINING\n",
    "\n",
    "\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119af003-4619-4510-b760-00eb9fcf245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries you used \n",
    "import os\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import tarfile\n",
    "from PIL import Image\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import transforms\n",
    "import shutil\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "## Import the data into the document\n",
    "image_dir = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images'\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
    "\n",
    "\n",
    "## CREATE A FILE WITH THE DESIRED IMAGES ONLY\n",
    "\n",
    "# Define the classifications to filter and their numeric mappings\n",
    "classification_mapping = {\n",
    "    \"Boeing 707\": 0,\n",
    "    \"Boeing 747\": 1,\n",
    "    \"A310\": 2,\n",
    "    \"Beechcraft 1900\": 3,\n",
    "    \"Gulfstream\": 4\n",
    "}\n",
    "\n",
    "# Define the file path\n",
    "file_path = 'images_family_train.txt'\n",
    "# Read the file and handle inconsistent line structures\n",
    "data = []\n",
    "with open(file_path, 'r') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) >= 2:  # Ensure at least two fields exist\n",
    "            number = parts[0]\n",
    "            classification = ' '.join(parts[1:])  # Combine remaining parts\n",
    "            data.append({\"Number\": number, \"Classification\": classification})\n",
    "        else:\n",
    "            print(f\"Skipping invalid line {i + 1}: {line.strip()}\")  # Debugging invalid lines\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Standardise the Classification column\n",
    "df['Classification'] = df['Classification'].str.strip()  # Remove extra spaces\n",
    "df['Classification'] = df['Classification'].str.title()  # Standardise capitalisation\n",
    "\n",
    "# Add numeric labels and filter invalid classifications\n",
    "df['Label'] = df['Classification'].map(classification_mapping)\n",
    "df = df.dropna(subset=['Label']).reset_index(drop=True)  # Remove rows with invalid classifications\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Read the file and collect classifications\n",
    "classifications = []\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) >= 2:  # Ensure there are at least two fields\n",
    "            classification = ' '.join(parts[1:]).strip()  # Combine fields after the first\n",
    "            classifications.append(classification)\n",
    "\n",
    "# Count the occurrences of each classification\n",
    "classification_counts = Counter(classifications)\n",
    "\n",
    "# Display the results\n",
    "print(\"Classification Counts:\")\n",
    "for classification, count in classification_counts.items():\n",
    "    print(f\"{classification}: {count}\")\n",
    "\n",
    "# Count the occurrences of each classification in the filtered DataFrame\n",
    "filtered_classification_counts = df['Classification'].value_counts()\n",
    "\n",
    "# Display the results\n",
    "print(\"Filtered Classification Counts:\")\n",
    "print(filtered_classification_counts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Create a folder with only the photos to keep\n",
    "\n",
    "# Path to your folder containing images\n",
    "image_folder_path = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images'\n",
    "\n",
    "\n",
    "relevant_codes = set(df['Number'])  # Convert to a set for faster lookup\n",
    "\n",
    "# Initialize a list to hold image tensors\n",
    "image_tensors = []\n",
    "\n",
    "# Define the image transformation (resize and convert to tensor)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize all images to a fixed size (e.g., 224x224)\n",
    "    transforms.ToTensor()  # Convert image to PyTorch tensor\n",
    "])\n",
    "\n",
    "# Iterate over files in the folder\n",
    "for image_file in os.listdir(image_folder_path):\n",
    "    # Extract the numeric part of the file name (assuming it's the code)\n",
    "    code = os.path.splitext(image_file)[0]\n",
    "    if code in relevant_codes and image_file.endswith('.jpg'):\n",
    "        # Load the image\n",
    "        image_path = os.path.join(image_folder_path, image_file)\n",
    "        img = Image.open(image_path).convert('RGB')  # Ensure 3 color channels (RGB)\n",
    "        \n",
    "        # Transform the image and append to the list\n",
    "        tensor = transform(img)\n",
    "        image_tensors.append(tensor)\n",
    "        print(f\"Loaded and transformed: {image_file}\")\n",
    "\n",
    "# Stack all tensors into a single tensor\n",
    "if image_tensors:\n",
    "    image_tensor_batch = torch.stack(image_tensors)\n",
    "    print(f\"Created a tensor of shape: {image_tensor_batch.shape}\")\n",
    "else:\n",
    "    print(\"No images matched the criteria!\")\n",
    "\n",
    "# Example tensor shape: [num_images, channels, height, width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e8a2fe-fb14-40b9-a4ea-22d90c99b036",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "\n",
    "\n",
    "#THIS SECOND SECTION WILL IMPORT THE TESTING DATA AND SETUP THE INFORMATION FOR F1 TESTING\n",
    "\n",
    "\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57de8950-c81d-41c8-a463-752b42ddc6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifications and their numeric mappings\n",
    "classification_mapping = {\n",
    "    \"Boeing 707\": 0,\n",
    "    \"Boeing 747\": 1,\n",
    "    \"A310\": 2,\n",
    "    \"Beechcraft 1900\": 3,\n",
    "    \"Gulfstream\": 4\n",
    "}\n",
    "\n",
    "# File path for the testing data classification file\n",
    "test_file_path = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images_family_test.txt'\n",
    "\n",
    "# Read and process the testing data file\n",
    "test_data = []\n",
    "with open(test_file_path, 'r') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) >= 2:  # Ensure there are at least two fields\n",
    "            number = parts[0]\n",
    "            classification = ' '.join(parts[1:])  # Combine remaining parts\n",
    "            test_data.append({\"Number\": number, \"Classification\": classification})\n",
    "        else:\n",
    "            print(f\"Skipping invalid line {i + 1}: {line.strip()}\")  # Debugging invalid lines\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df_test = pd.DataFrame(test_data)\n",
    "\n",
    "# Standardise the Classification column\n",
    "df_test['Classification'] = df_test['Classification'].str.strip()  # Remove extra spaces\n",
    "df_test['Classification'] = df_test['Classification'].str.title()  # Standardise capitalisation\n",
    "\n",
    "# Add numeric labels and filter invalid classifications\n",
    "df_test['Label'] = df_test['Classification'].map(classification_mapping)\n",
    "df_test = df_test.dropna(subset=['Label']).reset_index(drop=True)  # Remove rows with invalid classifications\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df_test)\n",
    "\n",
    "# Path to the testing images\n",
    "test_image_folder_path = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images'\n",
    "\n",
    "# Relevant test image codes\n",
    "relevant_test_codes = set(df_test['Number'])  # Convert to a set for faster lookup\n",
    "\n",
    "# Initialize a list to hold testing image tensors\n",
    "test_image_tensors = []\n",
    "\n",
    "# Define the image transformation (resize and convert to tensor)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize all images to a fixed size (e.g., 224x224)\n",
    "    transforms.ToTensor()  # Convert image to PyTorch tensor\n",
    "])\n",
    "\n",
    "# Iterate over files in the folder\n",
    "for image_file in os.listdir(test_image_folder_path):\n",
    "    # Extract the numeric part of the file name (assuming it's the code)\n",
    "    code = os.path.splitext(image_file)[0]\n",
    "    if code in relevant_test_codes and image_file.endswith('.jpg'):\n",
    "        # Load the image\n",
    "        image_path = os.path.join(test_image_folder_path, image_file)\n",
    "        img = Image.open(image_path).convert('RGB')  # Ensure 3 color channels (RGB)\n",
    "        \n",
    "        # Transform the image and append to the list\n",
    "        tensor = transform(img)\n",
    "        test_image_tensors.append(tensor)\n",
    "        print(f\"Loaded and transformed: {image_file}\")\n",
    "\n",
    "# Stack all tensors into a single tensor\n",
    "if test_image_tensors:\n",
    "    test_image_tensor_batch = torch.stack(test_image_tensors)\n",
    "    print(f\"Created a testing tensor of shape: {test_image_tensor_batch.shape}\")\n",
    "else:\n",
    "    print(\"No testing images matched the criteria!\")\n",
    "\n",
    "# Example tensor shape: [num_test_images, channels, height, width]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41296d9c-292b-4054-ba06-4846bd178750",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "\n",
    "\n",
    "#THIS 3rd SECTION WILL SETUP AND TRAIN THE NEURAL NETWORK\n",
    "\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ec509b-a14f-4f01-8b28-dadb60e5ee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self, num_classes=5):  # Default is 5 classes\n",
    "        super(BasicCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Max pooling\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 56 * 56, 128)  # Adjust input size for flattened conv output\n",
    "        self.fc2 = nn.Linear(128, num_classes)  # Output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply convolutional layers with ReLU activation and pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Flatten the tensor for fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Instantiate the CNN model\n",
    "cnn_model = BasicCNN(num_classes=len(classification_mapping))\n",
    "print(cnn_model)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "# Updated training function for CNN\n",
    "def train_cnn_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            # Move tensors to device if GPU is available (optional, if using CUDA)\n",
    "            # images, labels = images.to('cuda'), labels.to('cuda')\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)  # No need to flatten images for CNN\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "# Example DataLoader creation\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Prepare dataset and loader\n",
    "train_dataset = TensorDataset(image_tensor_batch, torch.tensor(df['Label'].values, dtype=torch.long))\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Train the CNN model\n",
    "train_cnn_model(cnn_model, train_loader, criterion, optimizer, num_epochs=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e445c65-1abb-4067-b28f-8b604297967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "\n",
    "\n",
    "#THIS 4th SECTION COMPLETES AN F1 TEST ON THE TRAINING DATA\n",
    "\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c17c58f-cac4-4f80-88f8-621b1c059dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the testing function for CNN\n",
    "def evaluate_cnn_model(model, test_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():  # No gradient calculation needed during testing\n",
    "        for images, labels in test_loader:\n",
    "            # Move tensors to device if GPU is available (optional, if using CUDA)\n",
    "            # images, labels = images.to('cuda'), labels.to('cuda')\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)  # CNN handles 2D/3D images directly\n",
    "            \n",
    "            # Get predictions (class with the highest score)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            # Store predictions and labels\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate Weighted F1-Score\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    print(f\"Weighted F1-Score: {f1}\")\n",
    "    \n",
    "    return f1\n",
    "\n",
    "# Prepare DataLoader for testing data\n",
    "test_dataset = TensorDataset(test_image_tensor_batch, torch.tensor(df_test['Label'].values, dtype=torch.long))\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Evaluate the CNN model on testing data\n",
    "f1_score_test = evaluate_cnn_model(cnn_model, test_loader)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
