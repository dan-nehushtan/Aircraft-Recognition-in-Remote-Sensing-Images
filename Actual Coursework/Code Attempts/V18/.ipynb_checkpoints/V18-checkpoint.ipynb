{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca0efc6-00eb-4414-9c55-fe635fe6c538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Define the folder containing the images\n",
    "image_folder = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images'\n",
    "\n",
    "# Paths to the text files\n",
    "train_label_file = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images_family_train.txt'\n",
    "test_label_file = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images_family_test.txt'\n",
    "val_label_file = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images_family_trainval.txt'\n",
    "\n",
    "# Define label mapping\n",
    "label_mapping = {\n",
    "    \"Boeing 707\": 0,\n",
    "    \"Boeing 727\": 1,\n",
    "    \"Boeing 737\": 2,\n",
    "    \"Boeing 747\": 3,\n",
    "    \"Boeing 757\": 4,\n",
    "    \"Boeing 767\": 5,\n",
    "    \"Boeing 777\": 6,\n",
    "    \"A300\": 7,\n",
    "    \"A310\": 8,\n",
    "    \"A320\": 9,\n",
    "    \"A330\": 10,\n",
    "    \"A340\": 11,\n",
    "    \"A380\": 12,\n",
    "    \"ATR-42\": 13,\n",
    "    \"ATR-72\": 14,\n",
    "    \"An-12\": 15,\n",
    "    \"BAE 146\": 16,\n",
    "    \"BAE-125\": 17,\n",
    "    \"Beechcraft 1900\": 18,\n",
    "    \"Boeing 717\": 19,\n",
    "    \"C-130\": 20,\n",
    "    \"C-47\": 21,\n",
    "    \"CRJ-200\": 22,\n",
    "    \"CRJ-700\": 23,\n",
    "    \"Cessna 172\": 24,\n",
    "    \"Cessna 208\": 25,\n",
    "    \"Cessna Citation\": 26,\n",
    "    \"Challenger 600\": 27,\n",
    "    \"DC-10\": 28,\n",
    "    \"DC-3\": 29,\n",
    "    \"DC-6\": 30,\n",
    "    \"DC-8\": 31,\n",
    "    \"DC-9\": 32,\n",
    "    \"DH-82\": 33,\n",
    "    \"DHC-1\": 34,\n",
    "    \"DHC-6\": 35,\n",
    "    \"Dash 8\": 36,\n",
    "    \"DR-400\": 37,\n",
    "    \"Dornier 328\": 38,\n",
    "    \"Embraer E-Jet\": 39,\n",
    "    \"EMB-120\": 40,\n",
    "    \"Embraer ERJ 145\": 41,\n",
    "    \"Embraer Legacy 600\": 42,\n",
    "    \"Eurofighter Typhoon\": 43,\n",
    "    \"F-16\": 44,\n",
    "    \"F/A-18\": 45,\n",
    "    \"Falcon 2000\": 46,\n",
    "    \"Falcon 900\": 47,\n",
    "    \"Fokker 100\": 48,\n",
    "    \"Fokker 50\": 49,\n",
    "    \"Fokker 70\": 50,\n",
    "    \"Global Express\": 51,\n",
    "    \"Gulfstream\": 52,\n",
    "    \"Hawk T1\": 53,\n",
    "    \"Il-76\": 54,\n",
    "    \"L-1011\": 55,\n",
    "    \"MD-11\": 56,\n",
    "    \"MD-80\": 57,\n",
    "    \"MD-90\": 58,\n",
    "    \"Metroliner\": 59,\n",
    "    \"King Air\": 60,\n",
    "    \"PA-28\": 61,\n",
    "    \"SR-20\": 62,\n",
    "    \"Saab 2000\": 63,\n",
    "    \"Saab 340\": 64,\n",
    "    \"Spitfire\": 65,\n",
    "    \"Tornado\": 66,\n",
    "    \"Tu-134\": 67,\n",
    "    \"Tu-154\": 68,\n",
    "    \"Yak-42\": 69\n",
    "}\n",
    "\n",
    "# Define transformations for image processing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize to 128x128\n",
    "    transforms.ToTensor()          # Convert to tensor\n",
    "])\n",
    "\n",
    "def count_labels(label_file):\n",
    "    label_counts = Counter()\n",
    "    with open(label_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(maxsplit=1)\n",
    "            if len(parts) == 2:\n",
    "                _, label = parts\n",
    "                label_counts[label] += 1\n",
    "    return label_counts\n",
    "\n",
    "def filter_data(label_file, top_labels):\n",
    "    image_data = []\n",
    "    labels = []\n",
    "\n",
    "    with open(label_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(maxsplit=1)\n",
    "            if len(parts) != 2:\n",
    "                continue  # Skip malformed lines\n",
    "            filename, label = parts\n",
    "            if label in top_labels:\n",
    "                image_path = os.path.join(image_folder, filename + \".jpg\")\n",
    "                try:\n",
    "                    if os.path.exists(image_path):\n",
    "                        image = Image.open(image_path).convert(\"RGB\")\n",
    "                        image_tensor = transform(image)\n",
    "                        image_data.append(image_tensor)\n",
    "                        labels.append(top_labels[label])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "    # Convert lists to PyTorch tensors\n",
    "    image_tensor = torch.stack(image_data)\n",
    "    label_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    return image_tensor, label_tensor\n",
    "\n",
    "# Count and select top 5 labels\n",
    "label_counts = count_labels(train_label_file)\n",
    "top_5_labels = dict(label_counts.most_common(5))\n",
    "print(\"Top 5 Labels:\", top_5_labels)\n",
    "\n",
    "# Remap top labels to sequential indices\n",
    "label_mapping_top5 = {label: idx for idx, (label, _) in enumerate(top_5_labels.items())}\n",
    "\n",
    "# Process training, validation, and test data for top 5 labels\n",
    "train_image_tensor, train_label_tensor = filter_data(train_label_file, label_mapping_top5)\n",
    "val_image_tensor, val_label_tensor = filter_data(val_label_file, label_mapping_top5)\n",
    "test_image_tensor, test_label_tensor = filter_data(test_label_file, label_mapping_top5)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_image_tensor, train_label_tensor)\n",
    "val_dataset = TensorDataset(val_image_tensor, val_label_tensor)\n",
    "test_dataset = TensorDataset(test_image_tensor, test_label_tensor)\n",
    "\n",
    "# Example usage of DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(\"DataLoaders for top 5 labels created successfully.\")\n",
    "\n",
    "# Define the CNN model\n",
    "class EnhancedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EnhancedCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc1 = nn.Linear(256 * 16 * 16, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, len(top_5_labels))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 256 * 16 * 16)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.dropout(self.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the enhanced model\n",
    "model = EnhancedCNN()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop with validation\n",
    "num_epochs = 15\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    history['train_loss'].append(running_loss / len(train_loader))\n",
    "    history['train_acc'].append(train_accuracy)\n",
    "\n",
    "    # Validate the model\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    history['val_loss'].append(val_loss / len(val_loader))\n",
    "    history['val_acc'].append(val_accuracy)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {running_loss/len(train_loader):.4f}, Validation Loss: {val_loss/len(val_loader):.4f}, Training Accuracy: {train_accuracy:.2f}%, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "# Evaluate on test data\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct_test / total_test\n",
    "print(f\"Test Loss: {test_loss / len(test_loader):.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Plot the training and validation accuracy and loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Train vs Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train vs Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
