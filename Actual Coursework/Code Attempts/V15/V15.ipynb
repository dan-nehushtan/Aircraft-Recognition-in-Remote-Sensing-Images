{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36967f72-f1bb-4ca1-983c-93ce90ef26e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DataLoader created successfully with batch size: 64\n",
      "Testing DataLoader created successfully with batch size: 64\n",
      "Epoch [1/15], Loss: 4.1378\n",
      "Epoch [2/15], Loss: 4.0729\n",
      "Epoch [3/15], Loss: 3.9789\n",
      "Epoch [4/15], Loss: 3.8675\n",
      "Epoch [5/15], Loss: 3.7341\n",
      "Epoch [6/15], Loss: 3.5566\n",
      "Epoch [7/15], Loss: 3.3014\n",
      "Epoch [8/15], Loss: 3.0455\n",
      "Epoch [9/15], Loss: 2.6671\n",
      "Epoch [10/15], Loss: 2.2090\n",
      "Epoch [11/15], Loss: 1.7782\n",
      "Epoch [12/15], Loss: 1.3288\n",
      "Epoch [13/15], Loss: 1.0242\n",
      "Epoch [14/15], Loss: 0.7911\n",
      "Epoch [15/15], Loss: 0.6255\n",
      "Accuracy on test data: 19.50%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define the folder containing the images\n",
    "image_folder = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images'\n",
    "\n",
    "# Paths to the text files\n",
    "train_label_file = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images_family_train.txt'\n",
    "validation_label_file = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images_family_validation.txt'\n",
    "test_label_file = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images_family_test.txt'\n",
    "\n",
    "# Define label mapping\n",
    "label_mapping = {\n",
    "    \"Boeing 707\": 0,\n",
    "    \"Boeing 727\": 1,\n",
    "    \"Boeing 737\": 2,\n",
    "    \"Boeing 747\": 3,\n",
    "    \"Boeing 757\": 4,\n",
    "    \"Boeing 767\": 5,\n",
    "    \"Boeing 777\": 6,\n",
    "    \"A300\": 7,\n",
    "    \"A310\": 8,\n",
    "    \"A320\": 9,\n",
    "    \"A330\": 10,\n",
    "    \"A340\": 11,\n",
    "    \"A380\": 12,\n",
    "    \"ATR-42\": 13,\n",
    "    \"ATR-72\": 14,\n",
    "    \"An-12\": 15,\n",
    "    \"BAE 146\": 16,\n",
    "    \"BAE-125\": 17,\n",
    "    \"Beechcraft 1900\": 18,\n",
    "    \"Boeing 717\": 19,\n",
    "    \"C-130\": 20,\n",
    "    \"C-47\": 21,\n",
    "    \"CRJ-200\": 22,\n",
    "    \"CRJ-700\": 23,\n",
    "    \"Cessna 172\": 24,\n",
    "    \"Cessna 208\": 25,\n",
    "    \"Cessna Citation\": 26,\n",
    "    \"Challenger 600\": 27,\n",
    "    \"DC-10\": 28,\n",
    "    \"DC-3\": 29,\n",
    "    \"DC-6\": 30,\n",
    "    \"DC-8\": 31,\n",
    "    \"DC-9\": 32,\n",
    "    \"DH-82\": 33,\n",
    "    \"DHC-1\": 34,\n",
    "    \"DHC-6\": 35,\n",
    "    \"Dash 8\": 36,\n",
    "    \"DR-400\": 37,\n",
    "    \"Dornier 328\": 38,\n",
    "    \"Embraer E-Jet\": 39,\n",
    "    \"EMB-120\": 40,\n",
    "    \"Embraer ERJ 145\": 41,\n",
    "    \"Embraer Legacy 600\": 42,\n",
    "    \"Eurofighter Typhoon\": 43,\n",
    "    \"F-16\": 44,\n",
    "    \"F/A-18\": 45,\n",
    "    \"Falcon 2000\": 46,\n",
    "    \"Falcon 900\": 47,\n",
    "    \"Fokker 100\": 48,\n",
    "    \"Fokker 50\": 49,\n",
    "    \"Fokker 70\": 50,\n",
    "    \"Global Express\": 51,\n",
    "    \"Gulfstream\": 52,\n",
    "    \"Hawk T1\": 53,\n",
    "    \"Il-76\": 54,\n",
    "    \"L-1011\": 55,\n",
    "    \"MD-11\": 56,\n",
    "    \"MD-80\": 57,\n",
    "    \"MD-90\": 58,\n",
    "    \"Metroliner\": 59,\n",
    "    \"King Air\": 60,\n",
    "    \"PA-28\": 61,\n",
    "    \"SR-20\": 62,\n",
    "    \"Saab 2000\": 63,\n",
    "    \"Saab 340\": 64,\n",
    "    \"Spitfire\": 65,\n",
    "    \"Tornado\": 66,\n",
    "    \"Tu-134\": 67,\n",
    "    \"Tu-154\": 68,\n",
    "    \"Yak-42\": 69\n",
    "}\n",
    "\n",
    "# Define transformations for image processing with data augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize to 128x128\n",
    "    transforms.RandomHorizontalFlip(),  # Random horizontal flip\n",
    "    transforms.RandomRotation(15),  # Random rotation within 15 degrees\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Random color jitter\n",
    "    transforms.ToTensor()  # Convert to tensor\n",
    "])\n",
    "\n",
    "def process_data(label_file):\n",
    "    image_data = []\n",
    "    labels = []\n",
    "\n",
    "    with open(label_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(maxsplit=1)\n",
    "            if len(parts) != 2:\n",
    "                continue  # Skip malformed lines\n",
    "            filename, label = parts\n",
    "            image_path = os.path.join(image_folder, filename + \".jpg\")\n",
    "\n",
    "            try:\n",
    "                if os.path.exists(image_path) and label in label_mapping:\n",
    "                    image = Image.open(image_path).convert(\"RGB\")\n",
    "                    image_tensor = transform(image)\n",
    "                    image_data.append(image_tensor)\n",
    "\n",
    "                    # Map label string to integer using label_mapping\n",
    "                    label_int = label_mapping[label]\n",
    "                    labels.append(label_int)\n",
    "                else:\n",
    "                    print(f\"Warning: Label '{label}' not found in label_mapping.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "    # Ensure consistent data sizes\n",
    "    assert len(image_data) == len(labels), \"Mismatch between image data and labels.\"\n",
    "\n",
    "    # Convert lists to PyTorch tensors\n",
    "    try:\n",
    "        image_tensor = torch.stack(image_data)  # Stack image data into a single tensor\n",
    "        label_tensor = torch.tensor(labels, dtype=torch.long)  # Ensure labels are integer tensors\n",
    "    except Exception as e:\n",
    "        print(f\"Error during tensor conversion: {e}\")\n",
    "\n",
    "    # Ensure tensors have the same first dimension\n",
    "    if image_tensor.size(0) != label_tensor.size(0):\n",
    "        raise ValueError(\"Image and label tensor size mismatch: \"\n",
    "                         f\"{image_tensor.size(0)} images vs {label_tensor.size(0)} labels.\")\n",
    "\n",
    "    return image_tensor, label_tensor\n",
    "\n",
    "# Process training data\n",
    "train_image_tensor, train_label_tensor = process_data(train_label_file)\n",
    "\n",
    "# Create training TensorDataset\n",
    "train_dataset = TensorDataset(train_image_tensor, train_label_tensor)\n",
    "\n",
    "# Process validation data\n",
    "validation_image_tensor, validation_label_tensor = process_data(validation_label_file)\n",
    "\n",
    "# Create validation TensorDataset\n",
    "validation_dataset = TensorDataset(validation_image_tensor, validation_label_tensor)\n",
    "\n",
    "# Example usage of DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(\"Training and Validation DataLoaders created successfully with batch size:\", batch_size)\n",
    "\n",
    "# Process testing data\n",
    "test_image_tensor, test_label_tensor = process_data(test_label_file)\n",
    "\n",
    "# Create testing TensorDataset\n",
    "test_dataset = TensorDataset(test_image_tensor, test_label_tensor)\n",
    "\n",
    "# Example usage of DataLoader for testing data\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(\"Testing DataLoader created successfully with batch size:\", batch_size)\n",
    "\n",
    "# Define the CNN model\n",
    "class EnhancedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EnhancedCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 256)\n",
    "        self.fc2 = nn.Linear(256, len(label_mapping))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 16 * 16)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the enhanced model\n",
    "model = EnhancedCNN()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop with validation\n",
    "num_epochs = 15\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Evaluate on validation data\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f\"Validation Loss: {val_loss/len(validation_loader):.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "# Evaluate on test data\n",
    "model.eval()\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Compute F1-score\n",
    "average_f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "print(f\"Average F1-Score: {average_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
