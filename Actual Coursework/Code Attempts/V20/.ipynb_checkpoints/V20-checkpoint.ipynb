{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac591a7d-5077-4b8e-aac0-057b24fe4ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Labels: {'Boeing 737': 267, 'Boeing 747': 133, 'A320': 133, 'A340': 133, 'Boeing 767': 100}\n",
      "DataLoaders for top 5 labels created successfully.\n",
      "Epoch [1/200], Train Loss: 1.6304, Test Loss: 1.5474, Train Acc: 0.2598, Test Acc: 0.3477, F1 Score: 0.1794, Time Remaining: 97.4628 mins\n",
      "Epoch [2/200], Train Loss: 1.5566, Test Loss: 1.5479, Train Acc: 0.3473, Test Acc: 0.3477, F1 Score: 0.1794, Time Remaining: 99.7934 mins\n",
      "Epoch [3/200], Train Loss: 1.5446, Test Loss: 1.5383, Train Acc: 0.3473, Test Acc: 0.3477, F1 Score: 0.1794, Time Remaining: 100.5978 mins\n",
      "Epoch [4/200], Train Loss: 1.5333, Test Loss: 1.5382, Train Acc: 0.3499, Test Acc: 0.3477, F1 Score: 0.1794, Time Remaining: 97.4066 mins\n",
      "Epoch [5/200], Train Loss: 1.5057, Test Loss: 1.5273, Train Acc: 0.3525, Test Acc: 0.3594, F1 Score: 0.2450, Time Remaining: 97.2882 mins\n",
      "Epoch [6/200], Train Loss: 1.4748, Test Loss: 1.5369, Train Acc: 0.3786, Test Acc: 0.3424, F1 Score: 0.2376, Time Remaining: 98.6073 mins\n",
      "Epoch [7/200], Train Loss: 1.4255, Test Loss: 1.5046, Train Acc: 0.3969, Test Acc: 0.3633, F1 Score: 0.2693, Time Remaining: 96.0221 mins\n",
      "Epoch [8/200], Train Loss: 1.3263, Test Loss: 1.5008, Train Acc: 0.4595, Test Acc: 0.3802, F1 Score: 0.3316, Time Remaining: 97.2518 mins\n",
      "Epoch [9/200], Train Loss: 1.1923, Test Loss: 1.5240, Train Acc: 0.5352, Test Acc: 0.3802, F1 Score: 0.3499, Time Remaining: 97.3470 mins\n",
      "Epoch [10/200], Train Loss: 1.0312, Test Loss: 1.7258, Train Acc: 0.6084, Test Acc: 0.3711, F1 Score: 0.3449, Time Remaining: 98.0319 mins\n",
      "Epoch [11/200], Train Loss: 0.8395, Test Loss: 1.7410, Train Acc: 0.6971, Test Acc: 0.3906, F1 Score: 0.3889, Time Remaining: 97.1431 mins\n",
      "Epoch [12/200], Train Loss: 0.6640, Test Loss: 1.9397, Train Acc: 0.7728, Test Acc: 0.3945, F1 Score: 0.3894, Time Remaining: 96.6930 mins\n",
      "Epoch [13/200], Train Loss: 0.4785, Test Loss: 2.2236, Train Acc: 0.8277, Test Acc: 0.4036, F1 Score: 0.4026, Time Remaining: 96.4635 mins\n",
      "Epoch [14/200], Train Loss: 0.3262, Test Loss: 2.5926, Train Acc: 0.8890, Test Acc: 0.3945, F1 Score: 0.3914, Time Remaining: 98.1759 mins\n",
      "Epoch [15/200], Train Loss: 0.2280, Test Loss: 2.9151, Train Acc: 0.9256, Test Acc: 0.3958, F1 Score: 0.3894, Time Remaining: 96.2941 mins\n",
      "Epoch [16/200], Train Loss: 0.1741, Test Loss: 3.0254, Train Acc: 0.9334, Test Acc: 0.3763, F1 Score: 0.3861, Time Remaining: 95.1444 mins\n",
      "Epoch [17/200], Train Loss: 0.1431, Test Loss: 3.3151, Train Acc: 0.9569, Test Acc: 0.4089, F1 Score: 0.3859, Time Remaining: 93.9611 mins\n",
      "Epoch [18/200], Train Loss: 0.0969, Test Loss: 3.6172, Train Acc: 0.9752, Test Acc: 0.4062, F1 Score: 0.4013, Time Remaining: 95.6300 mins\n",
      "Epoch [19/200], Train Loss: 0.0739, Test Loss: 3.7474, Train Acc: 0.9791, Test Acc: 0.4128, F1 Score: 0.4093, Time Remaining: 93.7777 mins\n",
      "Epoch [20/200], Train Loss: 0.0669, Test Loss: 3.7351, Train Acc: 0.9804, Test Acc: 0.4167, F1 Score: 0.4121, Time Remaining: 97.8546 mins\n",
      "Epoch [21/200], Train Loss: 0.0355, Test Loss: 3.9003, Train Acc: 0.9896, Test Acc: 0.3958, F1 Score: 0.3965, Time Remaining: 94.0390 mins\n",
      "Epoch [22/200], Train Loss: 0.0550, Test Loss: 4.1945, Train Acc: 0.9791, Test Acc: 0.4141, F1 Score: 0.4007, Time Remaining: 92.4113 mins\n",
      "Epoch [23/200], Train Loss: 0.0487, Test Loss: 4.5444, Train Acc: 0.9869, Test Acc: 0.4115, F1 Score: 0.3991, Time Remaining: 91.0243 mins\n",
      "Epoch [24/200], Train Loss: 0.0520, Test Loss: 3.7789, Train Acc: 0.9856, Test Acc: 0.3854, F1 Score: 0.3908, Time Remaining: 91.0294 mins\n",
      "Epoch [25/200], Train Loss: 0.0418, Test Loss: 4.0025, Train Acc: 0.9869, Test Acc: 0.3919, F1 Score: 0.3870, Time Remaining: 91.8422 mins\n",
      "Epoch [26/200], Train Loss: 0.0474, Test Loss: 4.0453, Train Acc: 0.9856, Test Acc: 0.3867, F1 Score: 0.3879, Time Remaining: 90.8013 mins\n",
      "Epoch [27/200], Train Loss: 0.0324, Test Loss: 4.3568, Train Acc: 0.9869, Test Acc: 0.4089, F1 Score: 0.3889, Time Remaining: 89.3840 mins\n",
      "Epoch [28/200], Train Loss: 0.0393, Test Loss: 4.0784, Train Acc: 0.9922, Test Acc: 0.3724, F1 Score: 0.3734, Time Remaining: 88.4389 mins\n",
      "Epoch [29/200], Train Loss: 0.0199, Test Loss: 4.4469, Train Acc: 0.9948, Test Acc: 0.3945, F1 Score: 0.3817, Time Remaining: 89.0061 mins\n",
      "Epoch [30/200], Train Loss: 0.0129, Test Loss: 4.7891, Train Acc: 0.9961, Test Acc: 0.3880, F1 Score: 0.3883, Time Remaining: 88.2158 mins\n",
      "Epoch [31/200], Train Loss: 0.0252, Test Loss: 4.6768, Train Acc: 0.9909, Test Acc: 0.4062, F1 Score: 0.3982, Time Remaining: 87.2169 mins\n",
      "Epoch [32/200], Train Loss: 0.0277, Test Loss: 4.4330, Train Acc: 0.9935, Test Acc: 0.3893, F1 Score: 0.3869, Time Remaining: 86.8211 mins\n",
      "Epoch [33/200], Train Loss: 0.0214, Test Loss: 4.2838, Train Acc: 0.9922, Test Acc: 0.3893, F1 Score: 0.3884, Time Remaining: 87.3958 mins\n",
      "Epoch [34/200], Train Loss: 0.0138, Test Loss: 4.6438, Train Acc: 0.9961, Test Acc: 0.4010, F1 Score: 0.3974, Time Remaining: 95.0590 mins\n",
      "Epoch [35/200], Train Loss: 0.0215, Test Loss: 4.6166, Train Acc: 0.9935, Test Acc: 0.4180, F1 Score: 0.4140, Time Remaining: 94.3639 mins\n",
      "Epoch [36/200], Train Loss: 0.0160, Test Loss: 5.1095, Train Acc: 0.9961, Test Acc: 0.4154, F1 Score: 0.4026, Time Remaining: 84.1449 mins\n",
      "Epoch [37/200], Train Loss: 0.0363, Test Loss: 4.1947, Train Acc: 0.9856, Test Acc: 0.3997, F1 Score: 0.4041, Time Remaining: 85.8251 mins\n",
      "Epoch [38/200], Train Loss: 0.0365, Test Loss: 4.2348, Train Acc: 0.9922, Test Acc: 0.3984, F1 Score: 0.4005, Time Remaining: 82.8897 mins\n",
      "Epoch [39/200], Train Loss: 0.0320, Test Loss: 4.1188, Train Acc: 0.9935, Test Acc: 0.3893, F1 Score: 0.3798, Time Remaining: 82.0958 mins\n",
      "Epoch [40/200], Train Loss: 0.0124, Test Loss: 4.7070, Train Acc: 0.9961, Test Acc: 0.3919, F1 Score: 0.3848, Time Remaining: 81.4180 mins\n",
      "Epoch [41/200], Train Loss: 0.0066, Test Loss: 5.2474, Train Acc: 0.9987, Test Acc: 0.3893, F1 Score: 0.3901, Time Remaining: 83.1029 mins\n",
      "Epoch [42/200], Train Loss: 0.0182, Test Loss: 5.7607, Train Acc: 0.9909, Test Acc: 0.4010, F1 Score: 0.3834, Time Remaining: 81.2158 mins\n",
      "Epoch [43/200], Train Loss: 0.0165, Test Loss: 4.9417, Train Acc: 0.9935, Test Acc: 0.3724, F1 Score: 0.3708, Time Remaining: 80.7250 mins\n",
      "Epoch [44/200], Train Loss: 0.0169, Test Loss: 5.3222, Train Acc: 0.9948, Test Acc: 0.4049, F1 Score: 0.3921, Time Remaining: 81.7227 mins\n",
      "Epoch [45/200], Train Loss: 0.0269, Test Loss: 5.0681, Train Acc: 0.9935, Test Acc: 0.3997, F1 Score: 0.3973, Time Remaining: 80.0996 mins\n",
      "Epoch [46/200], Train Loss: 0.0215, Test Loss: 4.5038, Train Acc: 0.9935, Test Acc: 0.3932, F1 Score: 0.3858, Time Remaining: 83.4794 mins\n",
      "Epoch [47/200], Train Loss: 0.0152, Test Loss: 4.5725, Train Acc: 0.9935, Test Acc: 0.4193, F1 Score: 0.4012, Time Remaining: 91.6153 mins\n",
      "Epoch [48/200], Train Loss: 0.0282, Test Loss: 4.8080, Train Acc: 0.9909, Test Acc: 0.4167, F1 Score: 0.4165, Time Remaining: 112.3316 mins\n",
      "Epoch [49/200], Train Loss: 0.0166, Test Loss: 4.7488, Train Acc: 0.9948, Test Acc: 0.4284, F1 Score: 0.4200, Time Remaining: 94.7848 mins\n",
      "Epoch [50/200], Train Loss: 0.0228, Test Loss: 4.8035, Train Acc: 0.9935, Test Acc: 0.4141, F1 Score: 0.4146, Time Remaining: 89.3757 mins\n",
      "Epoch [51/200], Train Loss: 0.0357, Test Loss: 4.6075, Train Acc: 0.9922, Test Acc: 0.4049, F1 Score: 0.4020, Time Remaining: 105.4148 mins\n",
      "Epoch [52/200], Train Loss: 0.0192, Test Loss: 4.7971, Train Acc: 0.9909, Test Acc: 0.4128, F1 Score: 0.4056, Time Remaining: 105.2938 mins\n",
      "Epoch [53/200], Train Loss: 0.0180, Test Loss: 4.8076, Train Acc: 0.9961, Test Acc: 0.4245, F1 Score: 0.4202, Time Remaining: 112.6798 mins\n",
      "Epoch [54/200], Train Loss: 0.0133, Test Loss: 4.9867, Train Acc: 0.9935, Test Acc: 0.4102, F1 Score: 0.4029, Time Remaining: 96.7274 mins\n",
      "Epoch [55/200], Train Loss: 0.0279, Test Loss: 4.5125, Train Acc: 0.9896, Test Acc: 0.4154, F1 Score: 0.3912, Time Remaining: 79.9006 mins\n",
      "Epoch [56/200], Train Loss: 0.0215, Test Loss: 4.3337, Train Acc: 0.9948, Test Acc: 0.3893, F1 Score: 0.3846, Time Remaining: 74.0766 mins\n",
      "Epoch [57/200], Train Loss: 0.0158, Test Loss: 4.6624, Train Acc: 0.9922, Test Acc: 0.3919, F1 Score: 0.3901, Time Remaining: 74.0509 mins\n",
      "Epoch [58/200], Train Loss: 0.0132, Test Loss: 5.0319, Train Acc: 0.9961, Test Acc: 0.3919, F1 Score: 0.3863, Time Remaining: 73.0273 mins\n",
      "Epoch [59/200], Train Loss: 0.0131, Test Loss: 5.2639, Train Acc: 0.9948, Test Acc: 0.4167, F1 Score: 0.4097, Time Remaining: 72.6878 mins\n",
      "Epoch [60/200], Train Loss: 0.0082, Test Loss: 5.5627, Train Acc: 0.9974, Test Acc: 0.4154, F1 Score: 0.4048, Time Remaining: 77.2936 mins\n",
      "Epoch [61/200], Train Loss: 0.0094, Test Loss: 5.1613, Train Acc: 0.9961, Test Acc: 0.4089, F1 Score: 0.4050, Time Remaining: 75.4442 mins\n",
      "Epoch [62/200], Train Loss: 0.0098, Test Loss: 4.9413, Train Acc: 0.9948, Test Acc: 0.4036, F1 Score: 0.3985, Time Remaining: 72.8039 mins\n",
      "Epoch [63/200], Train Loss: 0.0040, Test Loss: 5.2458, Train Acc: 1.0000, Test Acc: 0.4062, F1 Score: 0.3999, Time Remaining: 78.1224 mins\n",
      "Epoch [64/200], Train Loss: 0.0079, Test Loss: 5.4064, Train Acc: 0.9974, Test Acc: 0.3958, F1 Score: 0.3939, Time Remaining: 71.1689 mins\n",
      "Epoch [65/200], Train Loss: 0.0203, Test Loss: 5.6026, Train Acc: 0.9961, Test Acc: 0.4049, F1 Score: 0.3966, Time Remaining: 72.2546 mins\n",
      "Epoch [66/200], Train Loss: 0.0069, Test Loss: 5.7563, Train Acc: 0.9974, Test Acc: 0.3997, F1 Score: 0.3958, Time Remaining: 69.7711 mins\n",
      "Epoch [67/200], Train Loss: 0.0179, Test Loss: 5.0893, Train Acc: 0.9961, Test Acc: 0.4102, F1 Score: 0.3978, Time Remaining: 68.8178 mins\n",
      "Epoch [68/200], Train Loss: 0.0191, Test Loss: 4.9913, Train Acc: 0.9935, Test Acc: 0.4023, F1 Score: 0.3962, Time Remaining: 68.5640 mins\n",
      "Epoch [69/200], Train Loss: 0.0107, Test Loss: 5.3750, Train Acc: 0.9974, Test Acc: 0.4023, F1 Score: 0.3950, Time Remaining: 69.3968 mins\n",
      "Epoch [70/200], Train Loss: 0.0070, Test Loss: 5.0626, Train Acc: 0.9974, Test Acc: 0.3906, F1 Score: 0.3905, Time Remaining: 67.5189 mins\n",
      "Epoch [71/200], Train Loss: 0.0036, Test Loss: 5.1693, Train Acc: 1.0000, Test Acc: 0.3880, F1 Score: 0.3845, Time Remaining: 66.4138 mins\n",
      "Epoch [72/200], Train Loss: 0.0051, Test Loss: 5.3033, Train Acc: 0.9974, Test Acc: 0.3958, F1 Score: 0.3849, Time Remaining: 66.2666 mins\n",
      "Epoch [73/200], Train Loss: 0.0111, Test Loss: 5.2221, Train Acc: 0.9961, Test Acc: 0.3893, F1 Score: 0.3911, Time Remaining: 67.3763 mins\n",
      "Epoch [74/200], Train Loss: 0.0049, Test Loss: 5.1505, Train Acc: 0.9987, Test Acc: 0.3672, F1 Score: 0.3732, Time Remaining: 67.0109 mins\n",
      "Epoch [75/200], Train Loss: 0.0028, Test Loss: 5.3314, Train Acc: 1.0000, Test Acc: 0.3815, F1 Score: 0.3836, Time Remaining: 67.9960 mins\n",
      "Epoch [76/200], Train Loss: 0.0017, Test Loss: 5.5397, Train Acc: 1.0000, Test Acc: 0.4102, F1 Score: 0.4030, Time Remaining: 66.2704 mins\n",
      "Epoch [77/200], Train Loss: 0.0025, Test Loss: 5.6801, Train Acc: 0.9987, Test Acc: 0.4115, F1 Score: 0.4089, Time Remaining: 64.2093 mins\n",
      "Epoch [78/200], Train Loss: 0.0008, Test Loss: 5.9930, Train Acc: 1.0000, Test Acc: 0.4049, F1 Score: 0.4030, Time Remaining: 63.9616 mins\n",
      "Epoch [79/200], Train Loss: 0.0035, Test Loss: 6.0507, Train Acc: 0.9987, Test Acc: 0.4049, F1 Score: 0.3926, Time Remaining: 62.7461 mins\n",
      "Epoch [80/200], Train Loss: 0.0029, Test Loss: 6.0436, Train Acc: 0.9987, Test Acc: 0.4089, F1 Score: 0.3963, Time Remaining: 63.6781 mins\n",
      "Epoch [81/200], Train Loss: 0.0061, Test Loss: 5.9274, Train Acc: 0.9974, Test Acc: 0.3893, F1 Score: 0.3866, Time Remaining: 62.5948 mins\n",
      "Epoch [82/200], Train Loss: 0.0034, Test Loss: 6.4995, Train Acc: 0.9987, Test Acc: 0.4271, F1 Score: 0.4109, Time Remaining: 63.2013 mins\n",
      "Epoch [83/200], Train Loss: 0.0063, Test Loss: 5.8003, Train Acc: 0.9987, Test Acc: 0.4206, F1 Score: 0.4111, Time Remaining: 64.0043 mins\n",
      "Epoch [84/200], Train Loss: 0.0043, Test Loss: 5.6788, Train Acc: 0.9974, Test Acc: 0.4297, F1 Score: 0.4194, Time Remaining: 65.2048 mins\n",
      "Epoch [85/200], Train Loss: 0.0007, Test Loss: 5.7165, Train Acc: 1.0000, Test Acc: 0.4141, F1 Score: 0.4064, Time Remaining: 69.6745 mins\n",
      "Epoch [86/200], Train Loss: 0.0093, Test Loss: 5.2270, Train Acc: 0.9974, Test Acc: 0.4167, F1 Score: 0.4101, Time Remaining: 68.8971 mins\n",
      "Epoch [87/200], Train Loss: 0.0019, Test Loss: 5.0979, Train Acc: 0.9987, Test Acc: 0.4167, F1 Score: 0.4137, Time Remaining: 59.0369 mins\n",
      "Epoch [88/200], Train Loss: 0.0027, Test Loss: 5.3731, Train Acc: 1.0000, Test Acc: 0.4167, F1 Score: 0.4113, Time Remaining: 65.8195 mins\n",
      "Epoch [89/200], Train Loss: 0.0040, Test Loss: 5.5653, Train Acc: 0.9987, Test Acc: 0.4336, F1 Score: 0.4251, Time Remaining: 68.6072 mins\n",
      "Epoch [90/200], Train Loss: 0.0012, Test Loss: 5.5366, Train Acc: 1.0000, Test Acc: 0.4284, F1 Score: 0.4124, Time Remaining: 64.7931 mins\n",
      "Epoch [91/200], Train Loss: 0.0014, Test Loss: 5.5240, Train Acc: 1.0000, Test Acc: 0.4193, F1 Score: 0.4136, Time Remaining: 65.5463 mins\n",
      "Epoch [92/200], Train Loss: 0.0018, Test Loss: 5.6181, Train Acc: 0.9987, Test Acc: 0.4167, F1 Score: 0.4150, Time Remaining: 66.3270 mins\n",
      "Epoch [93/200], Train Loss: 0.0008, Test Loss: 6.0874, Train Acc: 1.0000, Test Acc: 0.4180, F1 Score: 0.4023, Time Remaining: 57.8404 mins\n",
      "Epoch [94/200], Train Loss: 0.0015, Test Loss: 6.2081, Train Acc: 1.0000, Test Acc: 0.4193, F1 Score: 0.4062, Time Remaining: 58.7317 mins\n",
      "Epoch [95/200], Train Loss: 0.0030, Test Loss: 5.9302, Train Acc: 0.9987, Test Acc: 0.4310, F1 Score: 0.4261, Time Remaining: 55.3962 mins\n",
      "Epoch [96/200], Train Loss: 0.0016, Test Loss: 6.0266, Train Acc: 1.0000, Test Acc: 0.4323, F1 Score: 0.4167, Time Remaining: 54.2204 mins\n",
      "Epoch [97/200], Train Loss: 0.0011, Test Loss: 6.0752, Train Acc: 1.0000, Test Acc: 0.4310, F1 Score: 0.4168, Time Remaining: 53.8215 mins\n",
      "Epoch [98/200], Train Loss: 0.0012, Test Loss: 6.0325, Train Acc: 1.0000, Test Acc: 0.4062, F1 Score: 0.4047, Time Remaining: 55.1310 mins\n",
      "Epoch [99/200], Train Loss: 0.0002, Test Loss: 6.6238, Train Acc: 1.0000, Test Acc: 0.4010, F1 Score: 0.4006, Time Remaining: 54.7430 mins\n",
      "Epoch [100/200], Train Loss: 0.0003, Test Loss: 7.0747, Train Acc: 1.0000, Test Acc: 0.4141, F1 Score: 0.4089, Time Remaining: 60.2292 mins\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 213\u001b[0m\n\u001b[1;32m    211\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m    212\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m--> 213\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    214\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    215\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    583\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[1;32m    348\u001b[0m     tensors,\n\u001b[1;32m    349\u001b[0m     grad_tensors_,\n\u001b[1;32m    350\u001b[0m     retain_graph,\n\u001b[1;32m    351\u001b[0m     create_graph,\n\u001b[1;32m    352\u001b[0m     inputs,\n\u001b[1;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    355\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define the folder containing the images\n",
    "image_folder = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images'\n",
    "\n",
    "# Paths to the text files\n",
    "train_label_file = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images_family_train.txt'\n",
    "test_label_file = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images_family_test.txt'\n",
    "val_label_file = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images_family_trainval.txt'\n",
    "\n",
    "# Define label mapping\n",
    "label_mapping = {\n",
    "    \"Boeing 707\": 0,\n",
    "    \"Boeing 727\": 1,\n",
    "    \"Boeing 737\": 2,\n",
    "    \"Boeing 747\": 3,\n",
    "    \"Boeing 757\": 4,\n",
    "    \"Boeing 767\": 5,\n",
    "    \"Boeing 777\": 6,\n",
    "    \"A300\": 7,\n",
    "    \"A310\": 8,\n",
    "    \"A320\": 9,\n",
    "    \"A330\": 10,\n",
    "    \"A340\": 11,\n",
    "    \"A380\": 12,\n",
    "    \"ATR-42\": 13,\n",
    "    \"ATR-72\": 14,\n",
    "    \"An-12\": 15,\n",
    "    \"BAE 146\": 16,\n",
    "    \"BAE-125\": 17,\n",
    "    \"Beechcraft 1900\": 18,\n",
    "    \"Boeing 717\": 19,\n",
    "    \"C-130\": 20,\n",
    "    \"C-47\": 21,\n",
    "    \"CRJ-200\": 22,\n",
    "    \"CRJ-700\": 23,\n",
    "    \"Cessna 172\": 24,\n",
    "    \"Cessna 208\": 25,\n",
    "    \"Cessna Citation\": 26,\n",
    "    \"Challenger 600\": 27,\n",
    "    \"DC-10\": 28,\n",
    "    \"DC-3\": 29,\n",
    "    \"DC-6\": 30,\n",
    "    \"DC-8\": 31,\n",
    "    \"DC-9\": 32,\n",
    "    \"DH-82\": 33,\n",
    "    \"DHC-1\": 34,\n",
    "    \"DHC-6\": 35,\n",
    "    \"Dash 8\": 36,\n",
    "    \"DR-400\": 37,\n",
    "    \"Dornier 328\": 38,\n",
    "    \"Embraer E-Jet\": 39,\n",
    "    \"EMB-120\": 40,\n",
    "    \"Embraer ERJ 145\": 41,\n",
    "    \"Embraer Legacy 600\": 42,\n",
    "    \"Eurofighter Typhoon\": 43,\n",
    "    \"F-16\": 44,\n",
    "    \"F/A-18\": 45,\n",
    "    \"Falcon 2000\": 46,\n",
    "    \"Falcon 900\": 47,\n",
    "    \"Fokker 100\": 48,\n",
    "    \"Fokker 50\": 49,\n",
    "    \"Fokker 70\": 50,\n",
    "    \"Global Express\": 51,\n",
    "    \"Gulfstream\": 52,\n",
    "    \"Hawk T1\": 53,\n",
    "    \"Il-76\": 54,\n",
    "    \"L-1011\": 55,\n",
    "    \"MD-11\": 56,\n",
    "    \"MD-80\": 57,\n",
    "    \"MD-90\": 58,\n",
    "    \"Metroliner\": 59,\n",
    "    \"King Air\": 60,\n",
    "    \"PA-28\": 61,\n",
    "    \"SR-20\": 62,\n",
    "    \"Saab 2000\": 63,\n",
    "    \"Saab 340\": 64,\n",
    "    \"Spitfire\": 65,\n",
    "    \"Tornado\": 66,\n",
    "    \"Tu-134\": 67,\n",
    "    \"Tu-154\": 68,\n",
    "    \"Yak-42\": 69\n",
    "}\n",
    "\n",
    "# Define transformations for image processing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize to 128x128\n",
    "    transforms.RandomHorizontalFlip(),  # Apply random horizontal flip\n",
    "    transforms.RandomRotation(15),  # Random rotation\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Apply color jitter\n",
    "    transforms.ToTensor(),          # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
    "])\n",
    "\n",
    "def count_labels(label_file):\n",
    "    label_counts = Counter()\n",
    "    with open(label_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(maxsplit=1)\n",
    "            if len(parts) == 2:\n",
    "                _, label = parts\n",
    "                label_counts[label] += 1\n",
    "    return label_counts\n",
    "\n",
    "def filter_data(label_file, top_labels):\n",
    "    image_data = []\n",
    "    labels = []\n",
    "\n",
    "    with open(label_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(maxsplit=1)\n",
    "            if len(parts) != 2:\n",
    "                continue  # Skip malformed lines\n",
    "            filename, label = parts\n",
    "            if label in top_labels:\n",
    "                image_path = os.path.join(image_folder, filename + \".jpg\")\n",
    "                try:\n",
    "                    if os.path.exists(image_path):\n",
    "                        image = Image.open(image_path).convert(\"RGB\")\n",
    "                        image_tensor = transform(image)\n",
    "                        image_data.append(image_tensor)\n",
    "                        labels.append(top_labels[label])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "    # Convert lists to PyTorch tensors\n",
    "    image_tensor = torch.stack(image_data)\n",
    "    label_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    return image_tensor, label_tensor\n",
    "\n",
    "# Count and select top 5 labels\n",
    "label_counts = count_labels(train_label_file)\n",
    "top_5_labels = dict(label_counts.most_common(5))\n",
    "print(\"Top 5 Labels:\", top_5_labels)\n",
    "\n",
    "# Remap top labels to sequential indices\n",
    "label_mapping_top5 = {label: idx for idx, (label, _) in enumerate(top_5_labels.items())}\n",
    "\n",
    "# Process training, validation, and test data for top 5 labels\n",
    "train_image_tensor, train_label_tensor = filter_data(train_label_file, label_mapping_top5)\n",
    "val_image_tensor, val_label_tensor = filter_data(val_label_file, label_mapping_top5)\n",
    "test_image_tensor, test_label_tensor = filter_data(test_label_file, label_mapping_top5)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_image_tensor, train_label_tensor)\n",
    "val_dataset = TensorDataset(val_image_tensor, val_label_tensor)\n",
    "test_dataset = TensorDataset(test_image_tensor, test_label_tensor)\n",
    "\n",
    "# Example usage of DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(\"DataLoaders for top 5 labels created successfully.\")\n",
    "\n",
    "# Define the CNN model\n",
    "class EnhancedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EnhancedCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc1 = nn.Linear(256 * 16 * 16, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, len(top_5_labels))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 256 * 16 * 16)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.dropout(self.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the enhanced model\n",
    "model = EnhancedCNN()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)  # Reduced learning rate for finer adjustments\n",
    "\n",
    "# Training loop with validation and F1 score calculation\n",
    "num_epochs = 200\n",
    "history = {'train_loss': [], 'test_loss': [], 'train_acc': [], 'test_acc': []}\n",
    "total_start_time = time.time()  # Start timing the entire process\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()  # Start timing the epoch\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    train_accuracy = correct_train / total_train\n",
    "    history['train_loss'].append(running_loss / len(train_loader))\n",
    "    history['train_acc'].append(train_accuracy)\n",
    "\n",
    "    # Evaluate on test data\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "            # Collect true and predicted labels for F1-score calculation\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    test_accuracy = correct_test / total_test\n",
    "    history['test_loss'].append(test_loss / len(test_loader))\n",
    "    history['test_acc'].append(test_accuracy)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    average_f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "    epoch_duration = time.time() - epoch_start_time  # Calculate epoch duration\n",
    "    remaining_time = epoch_duration * (num_epochs - epoch - 1)  # Estimate remaining time\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {running_loss/len(train_loader):.4f}, Test Loss: {test_loss/len(test_loader):.4f}, Train Acc: {train_accuracy:.4f}, Test Acc: {test_accuracy:.4f}, F1 Score: {average_f1:.4f}, Time Remaining: {remaining_time/60:.4f} mins\")\n",
    "\n",
    "# Calculate total training time\n",
    "total_time = time.time() - total_start_time\n",
    "print(f\"Total training time: {total_time/60:.2f} minutes\")\n",
    "\n",
    "# Plotting the results\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "# Plot Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, history['train_loss'], label='Training Loss')\n",
    "plt.plot(epochs, history['test_loss'], label='Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss vs Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, history['train_acc'], label='Training Accuracy')\n",
    "plt.plot(epochs, history['test_acc'], label='Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Test Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
