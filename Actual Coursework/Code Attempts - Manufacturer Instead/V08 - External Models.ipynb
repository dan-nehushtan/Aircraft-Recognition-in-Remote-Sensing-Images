{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec971fc8-f6be-42dd-b4c1-a7a3b5a0b929",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects a non-empty TensorList",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image_tensor, label_tensor\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Process data\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m train_image_tensor, train_label_tensor \u001b[38;5;241m=\u001b[39m filter_data(train_label_file, selected_labels)\n\u001b[1;32m     61\u001b[0m val_image_tensor, val_label_tensor \u001b[38;5;241m=\u001b[39m filter_data(val_label_file, selected_labels)\n\u001b[1;32m     62\u001b[0m test_image_tensor, test_label_tensor \u001b[38;5;241m=\u001b[39m filter_data(test_label_file, selected_labels)\n",
      "Cell \u001b[0;32mIn[5], line 55\u001b[0m, in \u001b[0;36mfilter_data\u001b[0;34m(label_file, selected_labels)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     53\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m image_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(image_data)\n\u001b[1;32m     56\u001b[0m label_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(labels, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image_tensor, label_tensor\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Data Processing\n",
    "# ----------------------------\n",
    "\n",
    "# Define the folder containing the images\n",
    "image_folder = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images'\n",
    "\n",
    "# Paths to the text files\n",
    "train_label_file = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images_manufacturer_train.txt'\n",
    "test_label_file = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images_manufacturer_test.txt'\n",
    "val_label_file = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images_manufacturer_trainval.txt'\n",
    "\n",
    "# Define label mapping\n",
    "selected_labels = {\"Boeing 737\": 0, \"A320\": 1, \"F-16\": 2, \"Cessna 172\": 3, \"MD-80\": 4}\n",
    "\n",
    "# Define transformations with higher resolution\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def filter_data(label_file, selected_labels):\n",
    "    image_data = []\n",
    "    labels = []\n",
    "    with open(label_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(maxsplit=1)\n",
    "            if len(parts) != 2:\n",
    "                continue\n",
    "            filename, label = parts\n",
    "            if label in selected_labels:\n",
    "                image_path = os.path.join(image_folder, filename + \".jpg\")\n",
    "                try:\n",
    "                    if os.path.exists(image_path):\n",
    "                        image = Image.open(image_path).convert(\"RGB\")\n",
    "                        image_tensor = transform(image)\n",
    "                        image_data.append(image_tensor)\n",
    "                        labels.append(selected_labels[label])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "    image_tensor = torch.stack(image_data)\n",
    "    label_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "    return image_tensor, label_tensor\n",
    "\n",
    "# Process data\n",
    "train_image_tensor, train_label_tensor = filter_data(train_label_file, selected_labels)\n",
    "val_image_tensor, val_label_tensor = filter_data(val_label_file, selected_labels)\n",
    "test_image_tensor, test_label_tensor = filter_data(test_label_file, selected_labels)\n",
    "\n",
    "# Create datasets and loaders\n",
    "batch_size = 16\n",
    "train_dataset = TensorDataset(train_image_tensor, train_label_tensor)\n",
    "val_dataset = TensorDataset(val_image_tensor, val_label_tensor)\n",
    "test_dataset = TensorDataset(test_image_tensor, test_label_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Model Setup\n",
    "# ----------------------------\n",
    "\n",
    "# Load pretrained ResNet50\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, len(selected_labels))  # Replace the final layer\n",
    "\n",
    "# Loss function with label smoothing\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Optimiser and scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Training and Validation\n",
    "# ----------------------------\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "val_f1_scores = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    val_accuracy = correct_val / total_val\n",
    "    val_f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "    val_losses.append(running_val_loss / len(val_loader))\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    val_f1_scores.append(val_f1)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Testing Phase\n",
    "# ----------------------------\n",
    "\n",
    "model.eval()\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "true_labels_test = []\n",
    "predicted_labels_test = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "        true_labels_test.extend(labels.cpu().numpy())\n",
    "        predicted_labels_test.extend(predicted.cpu().numpy())\n",
    "\n",
    "test_accuracy = correct_test / total_test\n",
    "test_f1 = f1_score(true_labels_test, predicted_labels_test, average='weighted')\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Plotting Results\n",
    "# ----------------------------\n",
    "\n",
    "# Plot Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot F1 Score\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), val_f1_scores, label='Validation F1 Score')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Validation F1 Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
