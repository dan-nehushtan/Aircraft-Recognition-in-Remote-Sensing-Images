{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b700a89-de9d-4bd7-8513-2fb87f4a7d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders for selected labels created successfully.\n",
      "Epoch [1/100], Train Loss: 1.3431, Test Loss: 1.3843, Train Acc: 0.4719, Test Acc: 0.4168, F1 Score: 0.3613\n",
      "Epoch [2/100], Train Loss: 1.2722, Test Loss: 1.3217, Train Acc: 0.4925, Test Acc: 0.4299, F1 Score: 0.3731\n",
      "Epoch [3/100], Train Loss: 1.2361, Test Loss: 1.2755, Train Acc: 0.5037, Test Acc: 0.5009, F1 Score: 0.3440\n",
      "Epoch [4/100], Train Loss: 1.2289, Test Loss: 1.2809, Train Acc: 0.4981, Test Acc: 0.4916, F1 Score: 0.3450\n",
      "Epoch [5/100], Train Loss: 1.2255, Test Loss: 1.3072, Train Acc: 0.5075, Test Acc: 0.4916, F1 Score: 0.3294\n",
      "Epoch [6/100], Train Loss: 1.2203, Test Loss: 1.2849, Train Acc: 0.5037, Test Acc: 0.4916, F1 Score: 0.3581\n",
      "Epoch [7/100], Train Loss: 1.1928, Test Loss: 1.2754, Train Acc: 0.5150, Test Acc: 0.4953, F1 Score: 0.3403\n",
      "Epoch [8/100], Train Loss: 1.1864, Test Loss: 1.2860, Train Acc: 0.5150, Test Acc: 0.4916, F1 Score: 0.3414\n",
      "Epoch [9/100], Train Loss: 1.1825, Test Loss: 1.2921, Train Acc: 0.5056, Test Acc: 0.4935, F1 Score: 0.3374\n",
      "Epoch [10/100], Train Loss: 1.1782, Test Loss: 1.2879, Train Acc: 0.5206, Test Acc: 0.4897, F1 Score: 0.3462\n",
      "Epoch [11/100], Train Loss: 1.1647, Test Loss: 1.2788, Train Acc: 0.5169, Test Acc: 0.4953, F1 Score: 0.3516\n",
      "Epoch [12/100], Train Loss: 1.1557, Test Loss: 1.2840, Train Acc: 0.5169, Test Acc: 0.4879, F1 Score: 0.3504\n",
      "Epoch [13/100], Train Loss: 1.1572, Test Loss: 1.2885, Train Acc: 0.5112, Test Acc: 0.4860, F1 Score: 0.3425\n",
      "Epoch [14/100], Train Loss: 1.1384, Test Loss: 1.2857, Train Acc: 0.5169, Test Acc: 0.4879, F1 Score: 0.3387\n",
      "Epoch [15/100], Train Loss: 1.1455, Test Loss: 1.2885, Train Acc: 0.5262, Test Acc: 0.4822, F1 Score: 0.3487\n",
      "Epoch [16/100], Train Loss: 1.1357, Test Loss: 1.2947, Train Acc: 0.5206, Test Acc: 0.4860, F1 Score: 0.3450\n",
      "Epoch [17/100], Train Loss: 1.1321, Test Loss: 1.2913, Train Acc: 0.5337, Test Acc: 0.4991, F1 Score: 0.3706\n",
      "Epoch [18/100], Train Loss: 1.1232, Test Loss: 1.2997, Train Acc: 0.5300, Test Acc: 0.4879, F1 Score: 0.3385\n",
      "Epoch [19/100], Train Loss: 1.1300, Test Loss: 1.2879, Train Acc: 0.5225, Test Acc: 0.4953, F1 Score: 0.3646\n",
      "Epoch [20/100], Train Loss: 1.1144, Test Loss: 1.2942, Train Acc: 0.5056, Test Acc: 0.4822, F1 Score: 0.3549\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define the folder containing the images\n",
    "image_folder = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images'\n",
    "\n",
    "# Paths to the text files\n",
    "train_label_file = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images_family_train.txt'\n",
    "test_label_file = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images_family_test.txt'\n",
    "val_label_file = '/Users/louieburns/Library/CloudStorage/OneDrive-UniversityofLeeds/Year 3/AI and Machine Learning/Term 1/Coursework 1/Actual Coursework/dataoriginal/images_family_trainval.txt'\n",
    "\n",
    "# Define label mapping\n",
    "label_mapping = {\n",
    "    \"Boeing 707\": 0,\n",
    "    \"Boeing 727\": 1,\n",
    "    \"Boeing 737\": 2,\n",
    "    \"Boeing 747\": 3,\n",
    "    \"Boeing 757\": 4,\n",
    "    \"Boeing 767\": 5,\n",
    "    \"Boeing 777\": 6,\n",
    "    \"A300\": 7,\n",
    "    \"A310\": 8,\n",
    "    \"A320\": 9,\n",
    "    \"A330\": 10,\n",
    "    \"A340\": 11,\n",
    "    \"A380\": 12,\n",
    "    \"ATR-42\": 13,\n",
    "    \"ATR-72\": 14,\n",
    "    \"An-12\": 15,\n",
    "    \"BAE 146\": 16,\n",
    "    \"BAE-125\": 17,\n",
    "    \"Beechcraft 1900\": 18,\n",
    "    \"Boeing 717\": 19,\n",
    "    \"C-130\": 20,\n",
    "    \"C-47\": 21,\n",
    "    \"CRJ-200\": 22,\n",
    "    \"CRJ-700\": 23,\n",
    "    \"Cessna 172\": 24,\n",
    "    \"Cessna 208\": 25,\n",
    "    \"Cessna Citation\": 26,\n",
    "    \"Challenger 600\": 27,\n",
    "    \"DC-10\": 28,\n",
    "    \"DC-3\": 29,\n",
    "    \"DC-6\": 30,\n",
    "    \"DC-8\": 31,\n",
    "    \"DC-9\": 32,\n",
    "    \"DH-82\": 33,\n",
    "    \"DHC-1\": 34,\n",
    "    \"DHC-6\": 35,\n",
    "    \"Dash 8\": 36,\n",
    "    \"DR-400\": 37,\n",
    "    \"Dornier 328\": 38,\n",
    "    \"Embraer E-Jet\": 39,\n",
    "    \"EMB-120\": 40,\n",
    "    \"Embraer ERJ 145\": 41,\n",
    "    \"Embraer Legacy 600\": 42,\n",
    "    \"Eurofighter Typhoon\": 43,\n",
    "    \"F-16\": 44,\n",
    "    \"F/A-18\": 45,\n",
    "    \"Falcon 2000\": 46,\n",
    "    \"Falcon 900\": 47,\n",
    "    \"Fokker 100\": 48,\n",
    "    \"Fokker 50\": 49,\n",
    "    \"Fokker 70\": 50,\n",
    "    \"Global Express\": 51,\n",
    "    \"Gulfstream\": 52,\n",
    "    \"Hawk T1\": 53,\n",
    "    \"Il-76\": 54,\n",
    "    \"L-1011\": 55,\n",
    "    \"MD-11\": 56,\n",
    "    \"MD-80\": 57,\n",
    "    \"MD-90\": 58,\n",
    "    \"Metroliner\": 59,\n",
    "    \"King Air\": 60,\n",
    "    \"PA-28\": 61,\n",
    "    \"SR-20\": 62,\n",
    "    \"Saab 2000\": 63,\n",
    "    \"Saab 340\": 64,\n",
    "    \"Spitfire\": 65,\n",
    "    \"Tornado\": 66,\n",
    "    \"Tu-134\": 67,\n",
    "    \"Tu-154\": 68,\n",
    "    \"Yak-42\": 69\n",
    "}\n",
    "\n",
    "# Select 5 specific classes to work with\n",
    "selected_labels = {\"Boeing 737\": 0, \"A320\": 1, \"F-16\": 2, \"Cessna 172\": 3, \"MD-80\": 4}\n",
    "\n",
    "# Define transformations for image processing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def filter_data(label_file, selected_labels):\n",
    "    image_data = []\n",
    "    labels = []\n",
    "\n",
    "    with open(label_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(maxsplit=1)\n",
    "            if len(parts) != 2:\n",
    "                continue\n",
    "            filename, label = parts\n",
    "            if label in selected_labels:\n",
    "                image_path = os.path.join(image_folder, filename + \".jpg\")\n",
    "                try:\n",
    "                    if os.path.exists(image_path):\n",
    "                        image = Image.open(image_path).convert(\"RGB\")\n",
    "                        image_tensor = transform(image)\n",
    "                        image_data.append(image_tensor)\n",
    "                        labels.append(selected_labels[label])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "    image_tensor = torch.stack(image_data)\n",
    "    label_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    return image_tensor, label_tensor\n",
    "\n",
    "train_image_tensor, train_label_tensor = filter_data(train_label_file, selected_labels)\n",
    "val_image_tensor, val_label_tensor = filter_data(val_label_file, selected_labels)\n",
    "test_image_tensor, test_label_tensor = filter_data(test_label_file, selected_labels)\n",
    "\n",
    "train_dataset = TensorDataset(train_image_tensor, train_label_tensor)\n",
    "val_dataset = TensorDataset(val_image_tensor, val_label_tensor)\n",
    "test_dataset = TensorDataset(test_image_tensor, test_label_tensor)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(\"DataLoaders for selected labels created successfully.\")\n",
    "\n",
    "# Improved CNN with residual connections\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1) if in_channels != out_channels else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut(x)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += shortcut\n",
    "        return self.relu(x)\n",
    "\n",
    "class EnhancedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EnhancedCNN, self).__init__()\n",
    "        self.layer1 = ResidualBlock(3, 32)\n",
    "        self.layer2 = ResidualBlock(32, 64)\n",
    "        self.layer3 = ResidualBlock(64, 128)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(128, len(selected_labels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = EnhancedCNN()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "train_accuracies, test_accuracies = [], []\n",
    "f1_scores = []\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    train_accuracy = correct_train / total_train\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    test_accuracy = correct_test / total_test\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    test_losses.append(test_loss / len(test_loader))\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {running_loss/len(train_loader):.4f}, Test Loss: {test_loss/len(test_loader):.4f}, Train Acc: {train_accuracy:.4f}, Test Acc: {test_accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_losses, label='Training Loss')\n",
    "plt.plot(epochs, test_losses, label='Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss vs Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(epochs, test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Test Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, f1_scores, label='F1 Score')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score vs Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
